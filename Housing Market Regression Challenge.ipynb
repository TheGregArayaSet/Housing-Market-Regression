{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Market Regression Challenge\n",
    "The housing market is one of the most crucial parts of the economy for every country. Purchasing a home is one of the primary ways to build wealth and savings for people. In this respect, predicting prices in the housing market is a very central topic in economic and financial circles.\n",
    "\n",
    "The house price dataset from Kaggle includes several features of the houses along with their sale prices at the time they are sold. So far, in this module, you built and implemented some models using this dataset.\n",
    "\n",
    "In this challenge, you are required to improve your model with respect to its prediction performance.\n",
    "\n",
    "To complete this challenge, submit a Jupyter notebook containing your solutions to the following tasks.\n",
    "\n",
    "Steps\n",
    "1. Load the houseprices data from Thinkful's database.\n",
    "2. Do data cleaning, exploratory data analysis, and feature engineering. You can use your previous work in this module. But make sure that your work is satisfactory.\n",
    "3. Now, split your data into train and test sets where 20% of the data resides in the test set.\n",
    "4. Build several linear regression models including Lasso, Ridge, or ElasticNet and train them in the training set. Use k-fold cross-validation to select the best hyperparameters if your models include one!\n",
    "5. Evaluate your best model on the test set.\n",
    "6. So far, you have only used the features in the dataset. However, house prices can be affected by many factors like economic activity and the interest rates at the time they are sold. So, try to find some useful factors that are not included in the dataset. Integrate these factors into your model and assess the prediction performance of your model. Discuss the implications of adding these external variables into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sqlalchemy import create_engine\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.stats import bartlett\n",
    "from scipy.stats import levene\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the houseprices data from Thinkful's database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mssubclass</th>\n",
       "      <th>mszoning</th>\n",
       "      <th>lotfrontage</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>street</th>\n",
       "      <th>alley</th>\n",
       "      <th>lotshape</th>\n",
       "      <th>landcontour</th>\n",
       "      <th>utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>poolarea</th>\n",
       "      <th>poolqc</th>\n",
       "      <th>fence</th>\n",
       "      <th>miscfeature</th>\n",
       "      <th>miscval</th>\n",
       "      <th>mosold</th>\n",
       "      <th>yrsold</th>\n",
       "      <th>saletype</th>\n",
       "      <th>salecondition</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  mssubclass mszoning  lotfrontage  lotarea street alley lotshape  \\\n",
       "0   1          60       RL         65.0     8450   Pave  None      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave  None      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave  None      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave  None      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave  None      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave  None      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave  None      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave  None      IR1   \n",
       "\n",
       "  landcontour utilities  ... poolarea poolqc  fence miscfeature miscval  \\\n",
       "0         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "1         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "2         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "3         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "4         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "5         Lvl    AllPub  ...        0   None  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "7         Lvl    AllPub  ...        0   None   None        Shed     350   \n",
       "\n",
       "  mosold yrsold  saletype  salecondition  saleprice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "\n",
       "[8 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "main_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# Close the connection after the query\n",
    "engine.dispose()\n",
    "\n",
    "# Take a look\n",
    "main_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Do data cleaning, exploratory data analysis, and feature engineering.\n",
    "\n",
    "#### First we'll clean the data.\n",
    "\n",
    "Let's start by creating a copy of the original data to clean without messing with the raw data. Then we can find all the columns that are missing data, and how many values each is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lotfrontage      259\n",
      "alley           1369\n",
      "masvnrtype         8\n",
      "masvnrarea         8\n",
      "bsmtqual          37\n",
      "bsmtcond          37\n",
      "bsmtexposure      38\n",
      "bsmtfintype1      37\n",
      "bsmtfintype2      38\n",
      "electrical         1\n",
      "fireplacequ      690\n",
      "garagetype        81\n",
      "garageyrblt       81\n",
      "garagefinish      81\n",
      "garagequal        81\n",
      "garagecond        81\n",
      "poolqc          1453\n",
      "fence           1179\n",
      "miscfeature     1406\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Copy the dataframe\n",
    "haus_df = main_df.copy()\n",
    "\n",
    "# Count the number of n/a values and print them out\n",
    "missing_list = haus_df.isna().sum()\n",
    "\n",
    "print(missing_list[missing_list > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the garage variables have a uniform number of missing values. Most likely when houses didn't have garages, these areas just didn't get filled in, so I think it's appropriate to label these as \"No Garage\". Similarly with the veneer variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "garages = ['garagetype', 'garagefinish', 'garagequal', 'garagecond']\n",
    "\n",
    "# Fill in empty garage string values with \"No Garage\"\n",
    "for garage in garages:\n",
    "    haus_df[garage].fillna('NoGarage', inplace=True)\n",
    "\n",
    "# Use 0 for the year the garage was built instead of a string\n",
    "haus_df['garageyrblt'].fillna(0.0, inplace=True)\n",
    "\n",
    "# Also fill in veneer variables\n",
    "haus_df['masvnrtype'].fillna('NoVeneer', inplace=True)\n",
    "\n",
    "# Area is a number so we mark it zero\n",
    "haus_df['masvnrarea'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is telling us the linear feet of street connected to properties, we can likely fill in the \"Lot Frontage\" variable with an average of what is seen by neighborhood, so let's go ahead with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the neighborhood and fill in the average of the neighborhood's lot frontage\n",
    "haus_df['lotfrontage'] = haus_df.groupby(['neighborhood'], sort=False)['lotfrontage'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as how there are some missing basement variables, but the \"TotalBsmtSF\" (Total square feet of basement area) variable has no missing values, we can say that any time this variable equals zero, the other basement values are either none or zero (where relevant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_list = ['bsmtqual', 'bsmtcond', 'bsmtexposure', 'bsmtfintype1', 'bsmtfintype2']\n",
    "\n",
    "for bsmt in bsmt_list:\n",
    "    haus_df.loc[haus_df.totalbsmtsf == 0, bsmt] = 'NoBasement'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fixed almost all of the null values in the basement variables, however there are still 2 null values to look at (one in bsmtexposure and the other in bsmtfintype2). Let's print these out with relevant basement values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalbsmtsf</th>\n",
       "      <th>bsmtqual</th>\n",
       "      <th>bsmtcond</th>\n",
       "      <th>bsmtexposure</th>\n",
       "      <th>bsmtfintype1</th>\n",
       "      <th>bsmtfintype2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>936</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     totalbsmtsf bsmtqual bsmtcond bsmtexposure bsmtfintype1 bsmtfintype2\n",
       "948          936       Gd       TA         None          Unf          Unf"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haus_df.loc[haus_df.bsmtexposure.isna() == True, ['totalbsmtsf', 'bsmtqual', 'bsmtcond',\n",
    "                                                  'bsmtexposure', 'bsmtfintype1', 'bsmtfintype2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalbsmtsf</th>\n",
       "      <th>bsmtqual</th>\n",
       "      <th>bsmtcond</th>\n",
       "      <th>bsmtexposure</th>\n",
       "      <th>bsmtfintype1</th>\n",
       "      <th>bsmtfintype2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>3206</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     totalbsmtsf bsmtqual bsmtcond bsmtexposure bsmtfintype1 bsmtfintype2\n",
       "333         3206       Gd       TA           No          GLQ         None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haus_df.loc[haus_df.bsmtfintype2.isna() == True, ['totalbsmtsf', 'bsmtqual', 'bsmtcond',\n",
    "                                                  'bsmtexposure', 'bsmtfintype1', 'bsmtfintype2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly both of these houses have basements, but maybe those values were just ignored in the data entry process. Let's assume that there is no exposure in the first example (948) and assign it as \"No\", and also assume that there was not a second finish type in the second example (333), or \"Unf\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_df.loc[haus_df.bsmtexposure.isna() == True, 'bsmtexposure'] = \"No\"\n",
    "\n",
    "haus_df.loc[haus_df.bsmtfintype2.isna() == True, 'bsmtfintype2'] = \"Unf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, if there aren't any fireplaces, obviously we can't measure their quality. Let's fill in any values that match this criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "haus_df.loc[haus_df.fireplaces == 0, 'fireplacequ'] = 'NoFireplace'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the above issues, if the pool's area is 0, then clearly it doesn't exist and we can't quantify its quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_df.loc[haus_df.poolarea == 0, 'poolqc'] = 'NoPool'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other oddity is that there is one house that has a null value for electricity, yet has central air which is run by electricity. So let's assume that this value can be filled in by the most common type of electricity that houses with central air has, which I have shown below is standard circuit breakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1364\n",
       "unique        4\n",
       "top       SBrkr\n",
       "freq       1282\n",
       "Name: electrical, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haus_df.loc[haus_df.centralair == \"Y\", 'electrical'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_df.loc[haus_df.electrical.isnull(), :] = \"SBrkr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last few empty values for \"alley\", \"fence\" and \"miscfeature\", I will simply replace these with more descriptive values, as the null value is expected in the data description as a lack of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_df.loc[haus_df.alley.isnull(), 'alley'] = 'NoAlley'\n",
    "\n",
    "haus_df.loc[haus_df.fence.isnull(), 'fence'] = 'NoFence'\n",
    "\n",
    "haus_df.loc[haus_df.miscfeature.isnull(), 'miscfeature'] = 'NoMiscFeatures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also one row where every value is labeled as 'SBrkr', so let's get rid of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_df = haus_df[haus_df['mssubclass'] != 'SBrkr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis and feature engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's make a copy of the house data so we can convert our categorical values to numeric values and find correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe\n",
    "corr_haus = haus_df.copy()\n",
    "\n",
    "# Create a list of columns that aren't already number values so we can give them dummy variables\n",
    "str_corr_list = ['mszoning', 'street', 'alley', 'lotshape', 'landcontour', 'utilities', 'lotconfig',\n",
    "       'landslope', 'neighborhood', 'condition1', 'condition2', 'bldgtype',\n",
    "       'housestyle', 'roofstyle', 'roofmatl', 'exterior1st', 'exterior2nd', 'masvnrtype',\n",
    "       'exterqual', 'extercond', 'foundation', 'bsmtqual', 'bsmtcond', 'bsmtexposure', 'bsmtfintype1',\n",
    "       'bsmtfintype2', 'heating', 'heatingqc', 'centralair', 'electrical', 'kitchenqual',\n",
    "       'functional', 'fireplacequ', 'garagetype', 'garagefinish', 'garagequal',\n",
    "       'garagecond', 'paveddrive', 'poolqc', 'fence', 'miscfeature', 'saletype', 'salecondition']\n",
    "\n",
    "# Get dummy variables for each category, and concatenate them back into the dataframe\n",
    "for col in str_corr_list:\n",
    "    corr_haus = pd.concat([corr_haus, pd.get_dummies(corr_haus[col])], axis=1)\n",
    "\n",
    "# Then remove the columns with these strings so we can calculate correlations\n",
    "for col in str_corr_list:\n",
    "    corr_haus = corr_haus.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other columns not listed above are all object variables however, so we have to update these to be integers so we can calculate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full list again\n",
    "tot_list = haus_df.columns.tolist()\n",
    "\n",
    "# Now we can just take the elements out that we didn't use last time\n",
    "int_corr_list = [x for x in tot_list if x not in str_corr_list]\n",
    "\n",
    "# iterate through this new list and make the columns numeric\n",
    "for icol in int_corr_list:\n",
    "    corr_haus[icol] = pd.to_numeric(corr_haus[icol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is a number, let's calculate the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overallqual     0.791069\n",
      "grlivarea       0.708618\n",
      "garagecars      0.640473\n",
      "garagearea      0.623423\n",
      "totalbsmtsf     0.613905\n",
      "firstflrsf      0.605968\n",
      "fullbath        0.560881\n",
      "Ex              0.553093\n",
      "totrmsabvgrd    0.533779\n",
      "yearbuilt       0.523273\n",
      "Name: saleprice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_mtrx = corr_haus.corr()\n",
    "corr_mtrx = pd.DataFrame(data=corr_mtrx)\n",
    "\n",
    "# We're just interested in relations to salesprice so we can now limit the correlations\n",
    "# to just this column\n",
    "sale_corr = corr_mtrx['saleprice']\n",
    "\n",
    "# Now get the top 10 positive correlations and take a look at them\n",
    "best_sale = sale_corr.sort_values(ascending=False).head(11)\n",
    "best_sale = best_sale.drop('saleprice')\n",
    "\n",
    "print(best_sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words, these variables are (in order):\n",
    "1. OverallQual: Overall material and finish quality\n",
    "2. GrLivArea: Above grade (ground) living area square feet\n",
    "3. GarageCars: Size of garage in car capacity\n",
    "4. GarageArea: Size of garage in square feet\n",
    "5. TotalBsmtSF: Total square feet of basement area\n",
    "6. 1stFlrSF: First Floor square feet\n",
    "7. FullBath: Full bathrooms above grade (ground)\n",
    "8. Ex: this is an entry in the \"overallqual\" column that is being picked up on its own from the dummy variables, so it can be left out\n",
    "9. TotRmsAbvGrd: Total rooms above ground (does not include bathrooms)\n",
    "10. YearBuilt: Original construction date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, I'll focus on the following features:\n",
    "1. OverallQual: Overall material and finish quality\n",
    "2. GrLivArea: Above grade (ground) living area square feet\n",
    "3. GarageCars: Size of garage in car capacity\n",
    "4. TotalBsmtSF: Total square feet of basement area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with just the features we want\n",
    "feat_haus = haus_df[['saleprice', 'overallqual','grlivarea', 'garagecars', 'totalbsmtsf']]\n",
    "\n",
    "# Get dummy variables for the overall quality column, and concatenate them back into the dataframe\n",
    "feat_haus = pd.concat([feat_haus, pd.get_dummies(feat_haus['overallqual'])], axis=1)\n",
    "\n",
    "# Then remove the columns with these strings so we can calculate correlations\n",
    "feat_haus = feat_haus.drop('overallqual', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to convert object variable columns to numbers\n",
    "int_list = ['saleprice', 'grlivarea', 'garagecars', 'totalbsmtsf']\n",
    "\n",
    "# iterate through this new list and make the columns numeric\n",
    "for icol in int_list:\n",
    "    feat_haus[icol] = pd.to_numeric(feat_haus[icol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the house prices model and assess the goodness of fit using F-test, R-squared, adjusted R-squared, AIC and BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              saleprice   R-squared:                       0.794\n",
      "Model:                            OLS   Adj. R-squared:                  0.792\n",
      "Method:                 Least Squares   F-statistic:                     463.8\n",
      "Date:                Sun, 04 Aug 2019   Prob (F-statistic):               0.00\n",
      "Time:                        15:45:50   Log-Likelihood:                -17380.\n",
      "No. Observations:                1459   AIC:                         3.479e+04\n",
      "Df Residuals:                    1446   BIC:                         3.485e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "1            1.431e+04   2.57e+04      0.557      0.577   -3.61e+04    6.47e+04\n",
      "2            5816.6216    2.1e+04      0.277      0.782   -3.54e+04     4.7e+04\n",
      "3            2486.0258   8667.463      0.287      0.774   -1.45e+04    1.95e+04\n",
      "4            1.967e+04   4658.806      4.221      0.000    1.05e+04    2.88e+04\n",
      "5            3.031e+04   4184.408      7.243      0.000    2.21e+04    3.85e+04\n",
      "6            4.177e+04   4735.474      8.820      0.000    3.25e+04    5.11e+04\n",
      "7             6.75e+04   5480.634     12.316      0.000    5.67e+04    7.83e+04\n",
      "8            1.089e+05   6673.885     16.318      0.000    9.58e+04    1.22e+05\n",
      "9            1.817e+05   8827.686     20.577      0.000    1.64e+05    1.99e+05\n",
      "10           1.982e+05   1.23e+04     16.148      0.000    1.74e+05    2.22e+05\n",
      "grlivarea      44.2402      2.350     18.825      0.000      39.630      48.850\n",
      "garagecars   1.813e+04   1642.388     11.039      0.000    1.49e+04    2.14e+04\n",
      "totalbsmtsf    24.7555      2.728      9.076      0.000      19.405      30.106\n",
      "==============================================================================\n",
      "Omnibus:                      678.413   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            61007.470\n",
      "Skew:                          -1.234   Prob(JB):                         0.00\n",
      "Kurtosis:                      34.583   Cond. No.                     5.25e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.25e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = feat_haus['saleprice']\n",
    "\n",
    "# X is the feature set\n",
    "X = feat_haus[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10,'grlivarea', 'garagecars', 'totalbsmtsf']]\n",
    "\n",
    "# Create a LinearRegression model object from scikit-learn's linear_model module.\n",
    "lrm = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the OLS model using statsmodels module\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Then print a summary report\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's F-statistic gives us an associated p-value of nearly zero, so this tells us that our chosen features are useful in explaining the the target variable, which in this case is the sale price. The R-squared value is 0.794 and the Adj R-Squared score is 0.792, which means that we are able to explain a large percentage of our variance with this model. However, this could probably perform somewhat better as it still leaves out ~20.8% of the variance explanation (i.e. 1-0.792). Lastly, the AIC and BIC scores are 0.0003479 and 0.0003485 respectively, which are very small values, and thus indicates this model has good explanation power.\n",
    "\n",
    "This model is mostly satisfactory but it could be improved. Notice that some of the features are not statistically significant, i.e. when the overall quality of the house gets a rating of 1, 2, or 3. I believe if we got rid of features that are not statistically significant we could improve on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              saleprice   R-squared (uncentered):                   0.967\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.966\n",
      "Method:                 Least Squares   F-statistic:                              4201.\n",
      "Date:                Sun, 04 Aug 2019   Prob (F-statistic):                        0.00\n",
      "Time:                        15:45:50   Log-Likelihood:                         -17380.\n",
      "No. Observations:                1459   AIC:                                  3.478e+04\n",
      "Df Residuals:                    1449   BIC:                                  3.483e+04\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "4             1.92e+04   4508.853      4.259      0.000    1.04e+04     2.8e+04\n",
      "5            2.977e+04   3960.014      7.518      0.000     2.2e+04    3.75e+04\n",
      "6            4.115e+04   4464.864      9.216      0.000    3.24e+04    4.99e+04\n",
      "7            6.678e+04   5158.937     12.944      0.000    5.67e+04    7.69e+04\n",
      "8             1.08e+05   6306.743     17.132      0.000    9.57e+04     1.2e+05\n",
      "9            1.807e+05   8481.734     21.304      0.000    1.64e+05    1.97e+05\n",
      "10           1.969e+05   1.19e+04     16.605      0.000    1.74e+05     2.2e+05\n",
      "grlivarea      44.4914      2.273     19.576      0.000      40.033      48.950\n",
      "garagecars    1.82e+04   1619.226     11.242      0.000     1.5e+04    2.14e+04\n",
      "totalbsmtsf    24.8851      2.712      9.177      0.000      19.566      30.204\n",
      "==============================================================================\n",
      "Omnibus:                      685.565   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            61734.026\n",
      "Skew:                          -1.257   Prob(JB):                         0.00\n",
      "Kurtosis:                      34.768   Cond. No.                     3.16e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.16e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# set X as the new feature set\n",
    "X = feat_haus[[4, 5, 6, 7, 8, 9, 10,'grlivarea', 'garagecars', 'totalbsmtsf']]\n",
    "\n",
    "# Recreate the LinearRegression model object\n",
    "lrm = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the OLS model\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Then print a summary report\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second model is an improvement and I am more comfortable moving forward with it now. The R-Squared and Adj R-Squared scores are higher, the p-value produced by the F-Statistics is still very close to zero, and the AIC and BIC scores even dropped a tiny bit. On top of this all of our variables are statistically significant in this model, unlike the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split your data into train and test sets where 20% of the data resides in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Split them up into X/Y Train/Test portions, giving 20% to the test size\n",
    "# Also give the random state a seed # so we can get the same results each run\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build several linear regression models including Lasso, Ridge, or ElasticNet and train them in the training set. Use k-fold cross-validation to select the best hyperparameters if your models include one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll write a function to print out all of the relevant statistics that I'll want to look at so I don't have to re-write it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_stats():\n",
    "    print(\"R-squared of the model in the training set is: {}\".format(lrm.score(x_train, y_train)))\n",
    "    print(\"-----Test set statistics-----\")\n",
    "    print(\"R-squared of the model in the test set is: {}\".format(lrm.score(x_test, y_test)))\n",
    "    print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "    print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "    print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "    print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in the training set is: 0.7770214565819715\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.8707494734498953\n",
      "Mean absolute error of the prediction is: 20418.828836253237\n",
      "Mean squared error of the prediction is: 718500399.1862898\n",
      "Root mean squared error of the prediction is: 26804.857753517175\n",
      "Mean absolute percentage error of the prediction is: 13.290880223412364\n"
     ]
    }
   ],
   "source": [
    "# Fit an OLS model\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds_train = lrm.predict(x_train)\n",
    "y_preds_test = lrm.predict(x_test)\n",
    "\n",
    "# Print out important stats\n",
    "model_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1e-10\n",
      "R-squared of the model in the training set is: 0.7770214565819715\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.8707494734498953\n",
      "Mean absolute error of the prediction is: 20418.828836251916\n",
      "Mean squared error of the prediction is: 718500399.1862442\n",
      "Root mean squared error of the prediction is: 26804.857753516324\n",
      "Mean absolute percentage error of the prediction is: 13.290880223410825\n"
     ]
    }
   ],
   "source": [
    "# Create a list of alpha values to use in the Lasso, Ridge, and ElasticNet models\n",
    "alphas = [np.power(10.0,p) for p in np.arange(-10,40,1)]\n",
    "\n",
    "# Fit a Lasso model\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=3)\n",
    "\n",
    "lasso_cv.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds_train = lasso_cv.predict(x_train)\n",
    "y_preds_test = lasso_cv.predict(x_test)\n",
    "\n",
    "# Print out important stats\n",
    "print(\"Best alpha value is: {}\".format(lasso_cv.alpha_))\n",
    "model_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1e-10\n",
      "R-squared of the model in the training set is: 0.7770214565819715\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.8707494734498953\n",
      "Mean absolute error of the prediction is: 20418.828836186596\n",
      "Mean squared error of the prediction is: 718500399.1837006\n",
      "Root mean squared error of the prediction is: 26804.857753468877\n",
      "Mean absolute percentage error of the prediction is: 13.290880223328047\n"
     ]
    }
   ],
   "source": [
    "# Fit a Ridge model\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=3)\n",
    "\n",
    "ridge_cv.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds_train = ridge_cv.predict(x_train)\n",
    "y_preds_test = ridge_cv.predict(x_test)\n",
    "\n",
    "# Print out important stats\n",
    "print(\"Best alpha value is: {}\".format(ridge_cv.alpha_))\n",
    "model_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1e-10\n",
      "R-squared of the model in the training set is: 0.7770214565819715\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.8707494734498953\n",
      "Mean absolute error of the prediction is: 20418.828797590108\n",
      "Mean squared error of the prediction is: 718500397.6819184\n",
      "Root mean squared error of the prediction is: 26804.85772545563\n",
      "Mean absolute percentage error of the prediction is: 13.290880174407235\n"
     ]
    }
   ],
   "source": [
    "# Fit an ElasticNet model\n",
    "elasticnet_cv = ElasticNetCV(alphas=alphas, cv=3)\n",
    "\n",
    "elasticnet_cv.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds_train = elasticnet_cv.predict(x_train)\n",
    "y_preds_test = elasticnet_cv.predict(x_test)\n",
    "\n",
    "# Print out important stats\n",
    "print(\"Best alpha value is: {}\".format(elasticnet_cv.alpha_))\n",
    "model_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate your best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Try to find some useful factors that are not included in the dataset. Integrate these factors into your model and assess the prediction performance of your model. Discuss the implications of adding these external variables into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
